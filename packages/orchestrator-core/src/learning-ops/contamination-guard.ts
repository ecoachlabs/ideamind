/**
 * Contamination Guard - Prevent model collapse
 *
 * Deduplicates near-duplicates, prevents training on own outputs, maintains diversity
 */

import pino from 'pino';
import { Pool } from 'pg';
import crypto from 'crypto';

const logger = pino({ name: 'contamination-guard' });

export interface ContaminationCheck {
  sampleId: string;
  contaminated: boolean;
  reason?: string;
  similarity?: number;
  nearDuplicates?: string[];
}

export class ContaminationGuard {
  constructor(
    private db: Pool,
    private simThreshold: number = 0.95 // Similarity threshold for near-duplicates
  ) {}

  /**
   * Check sample for contamination
   */
  async checkSample(sampleId: string, content: string, origin: string): Promise<ContaminationCheck> {
    logger.debug({ sampleId }, 'Checking sample for contamination');

    // Check 1: Self-loop detection (training on own output)
    if (origin === 'ai-generated') {
      const isSelfLoop = await this.detectSelfLoop(content);
      if (isSelfLoop) {
        return {
          sampleId,
          contaminated: true,
          reason: 'Self-loop detected: training on own model output',
        };
      }
    }

    // Check 2: Near-duplicate detection
    const nearDuplicates = await this.findNearDuplicates(content);
    if (nearDuplicates.length > 0) {
      return {
        sampleId,
        contaminated: true,
        reason: 'Near-duplicate found',
        nearDuplicates: nearDuplicates.map((d) => d.id),
        similarity: nearDuplicates[0].similarity,
      };
    }

    // Check 3: Diversity check
    const diversityScore = await this.checkDiversity(content);
    if (diversityScore < 0.3) {
      return {
        sampleId,
        contaminated: true,
        reason: 'Low diversity: content too similar to existing samples',
        similarity: 1 - diversityScore,
      };
    }

    return {
      sampleId,
      contaminated: false,
    };
  }

  /**
   * Detect self-loop (model trained on its own output)
   */
  private async detectSelfLoop(content: string): Promise<boolean> {
    // Check if content was previously generated by the system
    const contentHash = this.hashContent(content);

    const result = await this.db.query(
      `SELECT COUNT(*) as count
       FROM artifacts
       WHERE content_hash = $1 AND origin = 'ai-generated'`,
      [contentHash]
    );

    return parseInt(result.rows[0]?.count) > 0;
  }

  /**
   * Find near-duplicate samples
   */
  private async findNearDuplicates(content: string): Promise<Array<{ id: string; similarity: number }>> {
    // Simplified: use content hash similarity
    // In production, use embedding similarity (cosine distance)

    const contentHash = this.hashContent(content);

    // Find samples with same hash (exact duplicates)
    const exactDupes = await this.db.query(
      `SELECT id FROM dataset_samples WHERE input_hash = $1`,
      [contentHash]
    );

    if (exactDupes.rows.length > 0) {
      return exactDupes.rows.map((row) => ({ id: row.id, similarity: 1.0 }));
    }

    // Simplified: check for high text overlap
    // In production, use vector embeddings and cosine similarity
    const words = content.toLowerCase().split(/\s+/);
    const wordSet = new Set(words);

    const candidates = await this.db.query(
      `SELECT id, content FROM dataset_samples ORDER BY created_at DESC LIMIT 100`
    );

    const nearDupes: Array<{ id: string; similarity: number }> = [];

    for (const candidate of candidates.rows) {
      const candidateWords = candidate.content.toLowerCase().split(/\s+/);
      const candidateSet = new Set(candidateWords);

      const intersection = new Set([...wordSet].filter((x) => candidateSet.has(x)));
      const union = new Set([...wordSet, ...candidateSet]);

      const similarity = intersection.size / union.size;

      if (similarity >= this.simThreshold) {
        nearDupes.push({ id: candidate.id, similarity });
      }
    }

    return nearDupes;
  }

  /**
   * Check diversity of sample vs existing dataset
   */
  private async checkDiversity(content: string): Promise<number> {
    // Simplified diversity metric
    // In production, use topic modeling or cluster analysis

    const words = new Set(content.toLowerCase().split(/\s+/));

    // Get recent samples
    const recentSamples = await this.db.query(
      `SELECT content FROM dataset_samples ORDER BY created_at DESC LIMIT 50`
    );

    if (recentSamples.rows.length === 0) {
      return 1.0; // No samples yet, perfectly diverse
    }

    // Compute average Jaccard distance
    let totalDistance = 0;

    for (const sample of recentSamples.rows) {
      const sampleWords = new Set(sample.content.toLowerCase().split(/\s+/));
      const intersection = new Set([...words].filter((x) => sampleWords.has(x)));
      const union = new Set([...words, ...sampleWords]);

      const similarity = intersection.size / union.size;
      const distance = 1 - similarity;

      totalDistance += distance;
    }

    return totalDistance / recentSamples.rows.length;
  }

  /**
   * Prune contaminated samples from dataset
   */
  async pruneDataset(datasetId: string): Promise<number> {
    logger.info({ datasetId }, 'Pruning contaminated samples');

    let prunedCount = 0;

    // Get all samples in dataset
    const samples = await this.db.query(`SELECT id, content, origin FROM dataset_samples WHERE dataset_id = $1`, [
      datasetId,
    ]);

    for (const sample of samples.rows) {
      const check = await this.checkSample(sample.id, sample.content, sample.origin);

      if (check.contaminated) {
        await this.db.query(`DELETE FROM dataset_samples WHERE id = $1`, [sample.id]);
        prunedCount++;

        logger.debug({ sampleId: sample.id, reason: check.reason }, 'Pruned contaminated sample');
      }
    }

    logger.info({ datasetId, prunedCount }, 'Dataset pruning completed');

    return prunedCount;
  }

  /**
   * Hash content
   */
  private hashContent(content: string): string {
    return crypto.createHash('sha256').update(content).digest('hex');
  }

  /**
   * Get contamination statistics
   */
  async getStats(datasetId: string): Promise<{
    totalSamples: number;
    contaminated: number;
    cleanRate: number;
  }> {
    const result = await this.db.query(
      `SELECT COUNT(*) as total FROM dataset_samples WHERE dataset_id = $1`,
      [datasetId]
    );

    const totalSamples = parseInt(result.rows[0]?.total) || 0;

    // Simplified: check each sample (in production, cache results)
    let contaminatedCount = 0;

    const samples = await this.db.query(
      `SELECT id, content, origin FROM dataset_samples WHERE dataset_id = $1 LIMIT 100`,
      [datasetId]
    );

    for (const sample of samples.rows) {
      const check = await this.checkSample(sample.id, sample.content, sample.origin);
      if (check.contaminated) contaminatedCount++;
    }

    return {
      totalSamples,
      contaminated: contaminatedCount,
      cleanRate: totalSamples > 0 ? (totalSamples - contaminatedCount) / totalSamples : 1.0,
    };
  }
}

// No new migration needed - uses existing tables
`;
