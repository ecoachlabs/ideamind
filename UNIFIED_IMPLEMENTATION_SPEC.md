# IdeaMine Unified Implementation Specification
**Combining Orchestrator.txt + Phase.txt Gaps into One Actionable Plan**

**Date:** 2025-10-19
**Source Documents:**
- `orchestrator.txt` (303 lines) - Mothership Orchestrator authority & capabilities
- `phase.txt` (213 lines) - Phase Coordinator implementation blueprint

**Status:** ğŸ”´ **COMPREHENSIVE IMPLEMENTATION REQUIRED**

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Architecture Overview](#architecture-overview)
3. [Foundation Layer (Week 1-2)](#foundation-layer)
4. [Autonomy Layer (Week 3-4)](#autonomy-layer)
5. [Execution Layer (Week 5-6)](#execution-layer)
6. [Resilience Layer (Week 7-8)](#resilience-layer)
7. [Observability Layer (Week 9-10)](#observability-layer)
8. [Production Hardening (Week 11)](#production-hardening)
9. [Database Schema](#database-schema)
10. [File Structure](#file-structure)
11. [Configuration Files](#configuration-files)
12. [Testing Strategy](#testing-strategy)

---

## Executive Summary

This document combines all gaps identified from **orchestrator.txt** and **phase.txt** specifications into a single, ordered implementation plan. The plan is organized into 6 layers, each building on the previous, ensuring incremental value delivery.

### Gap Summary

| Layer | Components | Files to Create | Files to Modify | DB Tables | Effort (Days) |
|-------|-----------|-----------------|-----------------|-----------|---------------|
| **Foundation** | YAML Configs, Schemas, Events | 24 | 5 | 2 | 10 |
| **Autonomy** | Q/A/V Triad, Knowledge Refinery Integration | 8 | 3 | 1 | 8 |
| **Execution** | Job Queue, WorkerPool, Scheduler, Checkpoints | 12 | 4 | 4 | 12 |
| **Resilience** | Heartbeats, Unsticker, Retries, Fallbacks | 9 | 6 | 1 | 8 |
| **Observability** | Run Ledger, Metrics, OTEL, Provenance | 7 | 5 | 3 | 8 |
| **Hardening** | Dashboards, Tests, RBAC, Versioning | 15 | 8 | 2 | 9 |
| **TOTAL** | **71** | **75** | **31** | **13** | **55 days** |

### Critical Path

```
Foundation â†’ Autonomy â†’ Execution â†’ Resilience â†’ Observability â†’ Hardening
   (10d)       (8d)        (12d)        (8d)          (8d)           (9d)
```

**MVP Delivery:** After Execution Layer (Week 6) - 30 days
**Full Spec Compliance:** Week 11 - 55 days

---

## Architecture Overview

### Current vs. Target Architecture

**Current (What We Have):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Enhanced Orchestrator (MO)         â”‚
â”‚  - Basic state machine                  â”‚
â”‚  - Sequential phase execution           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                      â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase   â”‚          â”‚ Phase   â”‚    â”‚ Phase   â”‚   â”‚  ...    â”‚
â”‚ Coord 1 â”‚          â”‚ Coord 2 â”‚    â”‚ Coord 3 â”‚   â”‚ Coord12 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                    â”‚              â”‚             â”‚
  â”Œâ”€â”€â”´â”€â”€â”              â”Œâ”€â”€â”´â”€â”€â”        â”Œâ”€â”€â”´â”€â”€â”       â”Œâ”€â”€â”´â”€â”€â”
  â”‚Agentâ”‚              â”‚Agentâ”‚        â”‚Agentâ”‚       â”‚Agentâ”‚
  â””â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”˜
```

**Target (Full Spec):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Mothership Orchestrator (MO)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Run Planner  â”‚ DAG Executor  â”‚ Self-Exec    â”‚ Auto-Doer    â”‚ â”‚
â”‚  â”‚              â”‚ (Parallel)    â”‚ Mode (SEM)   â”‚ Creator      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    â”‚                    â”‚
    â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase Coord 1   â”‚ â”‚ Phase Coord 6a  â”‚ â”‚ Phase Coord 6   â”‚
â”‚   (Intake)      â”‚ â”‚  (Security)     â”‚ â”‚ (Story Loop)    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Plan        â”‚ â”‚ â”‚ â”‚ Plan        â”‚ â”‚ â”‚ â”‚ Plan        â”‚ â”‚
â”‚ â”‚ Dispatch    â”‚ â”‚ â”‚ â”‚ Dispatch    â”‚ â”‚ â”‚ â”‚ Dispatch    â”‚ â”‚
â”‚ â”‚ Guard       â”‚ â”‚ â”‚ â”‚ Guard       â”‚ â”‚ â”‚ â”‚ Guard       â”‚ â”‚
â”‚ â”‚ Heal        â”‚ â”‚ â”‚ â”‚ Heal        â”‚ â”‚ â”‚ â”‚ Heal        â”‚ â”‚
â”‚ â”‚ Clarify     â”‚ â”‚ â”‚ â”‚ Clarify     â”‚ â”‚ â”‚ â”‚ Clarify     â”‚ â”‚
â”‚ â”‚ Handoff     â”‚ â”‚ â”‚ â”‚ Handoff     â”‚ â”‚ â”‚ â”‚ Handoff     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚
â”‚  FAN-OUT        â”‚ â”‚  FAN-OUT (||)   â”‚ â”‚  FAN-OUT        â”‚
â”‚    â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”   â”‚ â”‚   â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”  â”‚ â”‚    â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”   â”‚
â”‚    â–¼  â–¼  â–¼  â–¼   â”‚ â”‚   â–¼ â–¼ â–¼ â–¼ â–¼ â–¼  â”‚ â”‚    â–¼  â–¼  â–¼  â–¼   â”‚
â”‚   A1 A2 A3      â”‚ â”‚  A1 A2 A3 A4... â”‚ â”‚   A1 A2 A3      â”‚
â”‚    â”‚  â”‚  â”‚       â”‚ â”‚   â”‚ â”‚ â”‚ â”‚ â”‚ â”‚  â”‚ â”‚    â”‚  â”‚  â”‚       â”‚
â”‚    â””â”€â”€â”´â”€â”€â”´â”€â”€â”   â”‚ â”‚   â””â”€â”´â”€â”´â”€â”´â”€â”´â”€â”˜  â”‚ â”‚    â””â”€â”€â”´â”€â”€â”´â”€â”€â”   â”‚
â”‚             â–¼   â”‚ â”‚        â–¼        â”‚ â”‚             â–¼   â”‚
â”‚        AGGREGATEâ”‚ â”‚   AGGREGATE     â”‚ â”‚        AGGREGATEâ”‚
â”‚             â”‚   â”‚ â”‚        â”‚        â”‚ â”‚             â”‚   â”‚
â”‚             â–¼   â”‚ â”‚        â–¼        â”‚ â”‚             â–¼   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚     â”‚  Q/A/V    â”‚ â”‚ â”‚  Q/A/V       â”‚ â”‚ â”‚  Q/A/V       â”‚â”‚
â”‚     â”‚  Triad    â”‚ â”‚ â”‚  Triad       â”‚ â”‚ â”‚  Triad       â”‚â”‚
â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚           â–¼     â”‚ â”‚        â–¼        â”‚ â”‚        â–¼        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚     â”‚ Guards    â”‚ â”‚ â”‚ Guards       â”‚ â”‚ â”‚ Guards       â”‚â”‚
â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚           â–¼     â”‚ â”‚        â–¼        â”‚ â”‚        â–¼        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚     â”‚ Gate      â”‚ â”‚ â”‚ Gate         â”‚ â”‚ â”‚ Gate         â”‚â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  QA Phase    â”‚
                    â”‚ (waits both) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Infrastructure Services                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Job Queue  â”‚WorkerPool â”‚Scheduler  â”‚Timer Svc  â”‚Knowledge Refineryâ”‚
â”‚(Redis)    â”‚(Sandboxes)â”‚(Sharding) â”‚(Durable)  â”‚(Fission/Fusion) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Event Bus  â”‚Recorder   â”‚Gatekeeper â”‚Supervisor â”‚Dispatcher       â”‚
â”‚(Topics)   â”‚(Ledger)   â”‚(Rubrics)  â”‚(Unstick)  â”‚(Routing)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Foundation Layer (Week 1-2)

**Goal:** Establish contracts, configs, and data structures for all 12 phases

### 1.1 Phase YAML Configurations (12 files)

**Requirement:** orchestrator.txt:256-275, phase.txt:357-456

**Files to Create:**
```
config/
  intake.yaml
  ideation.yaml
  critique.yaml
  prd.yaml
  bizdev.yaml
  architecture.yaml
  build.yaml
  security.yaml
  story-loop.yaml
  qa.yaml
  aesthetic.yaml
  release.yaml
  beta.yaml
```

**Template Structure (all phases):**
```yaml
# config/[phase].yaml
phase: PHASE_NAME
parallelism: sequential | 2 | 3 | 4 | partial | iterative
agents:
  - AgentName1
  - AgentName2
  - AgentName3
budgets:
  tokens: 700000              # per phase
  tools_minutes: 60           # minutes
  gpu_hours: 0                # optional
rubrics:
  grounding_min: 0.85
  contradictions_max: 0
  coverage_min: 0.80
  # phase-specific rubrics
allowlisted_tools:
  - tool.phase.tool1
  - tool.phase.tool2
  - guard.guardName1
  - guard.guardName2
heartbeat_seconds: 60
stall_threshold_heartbeats: 3
refinery:
  fission_min_coverage: 0.90
  fusion_min_consensus: 0.85
timebox: PT2H                 # ISO8601 duration
```

**Specific Configs (from phase.txt):**

**config/intake.yaml:**
```yaml
phase: INTAKE
parallelism: sequential
agents:
  - IntakeClassifierAgent
  - IntakeExpanderAgent
  - IntakeValidatorAgent
budgets:
  tokens: 700000
  tools_minutes: 60
rubrics:
  ambiguity_max: 0.10
  blockers_max: 0
  grounding_min: 0.85
  contradictions_max: 0
  feasibility_required: true
allowlisted_tools:
  - tool.intake.normalizer
  - tool.intake.ontology
  - tool.intake.priorart
  - tool.intake.feasibility
  - guard.claimMiner
  - guard.sourceTagger
  - guard.contradictionScan
heartbeat_seconds: 60
stall_threshold_heartbeats: 3
refinery:
  fission_min_coverage: 0.90
  fusion_min_consensus: 0.85
timebox: PT1H
```

**config/ideation.yaml:**
```yaml
phase: IDEATION
parallelism: 4                # All 4 agents in parallel!
agents:
  - StrategyAgent
  - CompetitiveAgent
  - TechStackAgent
  - PersonaAgent
budgets:
  tokens: 2000000             # 2M tokens
  tools_minutes: 180
rubrics:
  usecase_coverage_min: 0.85
  personas_count: [3, 5]      # 3-5 personas required
  citations_required: true
  grounding_min: 0.85
allowlisted_tools:
  - tool.ideation.usecases
  - tool.ideation.personas
  - tool.ideation.kpiDesigner
  - tool.ideation.analogy
  - tool.ideation.divergeConverge
  - tool.ideation.abuseSeeds
  - guard.citationCheck
  - guard.speculativeLabeler
heartbeat_seconds: 60
stall_threshold_heartbeats: 3
refinery:
  fission_min_coverage: 0.90
  fusion_min_consensus: 0.85
timebox: PT3H
```

**config/security.yaml:**
```yaml
phase: SECURITY
parallelism: parallel         # All 9 agents in parallel
agents:
  - secrets-hygiene-agent
  - sca-agent
  - sast-agent
  - iac-policy-agent
  - container-hardening-agent
  - privacy-dpia-agent
  - threat-model-agent
  - dast-agent
  - supply-chain-agent
budgets:
  tokens: 1500000
  tools_minutes: 600          # 10 hours for security scans
rubrics:
  critical_cves_max: 0        # HARD: no critical CVEs
  secrets_max: 0              # HARD: no secrets
  critical_sast_max: 0        # HARD: no critical SAST findings
  high_cves_max: 0            # can be waived
  sbom_coverage_min: 1.0      # 100% SBOM coverage
  signatures_required: true
allowlisted_tools:
  - guard.secretScan          # TruffleHog + Gitleaks
  - tool.code.depScan         # Trivy + OSV
  - tool.code.staticPack      # Semgrep + Bandit
  - tool.iac.conftest
  - tool.container.bench
  - tool.privacy.dpia
  - tool.threat.stride
  - tool.dast.zap
  - tool.sbom.cyclonedx
  - tool.signing.cosign
heartbeat_seconds: 60
stall_threshold_heartbeats: 5   # longer timeout for security scans
refinery:
  fission_min_coverage: 0.95
  fusion_min_consensus: 0.90
timebox: PT1H30M
```

**Effort:** 2 days (draft all 12 configs)

---

### 1.2 JSON Schema Definitions (Strict Contracts)

**Requirement:** phase.txt:65-122

**Files to Create:**

**packages/schemas/src/phase/phase-context.ts:**
```typescript
/**
 * PhaseContext - Input contract for all Phase Coordinators
 * Spec: phase.txt:65-80
 */

export const PhaseContextSchema = {
  $schema: 'https://json-schema.org/draft/2020-12/schema',
  $id: 'schema.phase.context.v1',
  type: 'object',
  required: ['phase', 'inputs', 'budgets', 'rubrics', 'timebox'],
  properties: {
    phase: {
      type: 'string',
      enum: ['INTAKE', 'IDEATION', 'CRITIQUE', 'PRD', 'BIZDEV', 'ARCHITECTURE',
             'BUILD', 'SECURITY', 'STORY_LOOP', 'QA', 'AESTHETIC', 'RELEASE', 'BETA']
    },
    inputs: { type: 'object' },
    dependencies: {
      type: 'array',
      items: { type: 'string' }
    },
    budgets: {
      type: 'object',
      required: ['tokens', 'tools_minutes'],
      properties: {
        tokens: { type: 'number', minimum: 0 },
        tools_minutes: { type: 'number', minimum: 0 },
        gpu_hours: { type: 'number', minimum: 0 }
      },
      additionalProperties: false
    },
    rubrics: { type: 'object' },
    timebox: {
      type: 'string',
      pattern: '^PT\\d+H(\\d+M)?(\\d+S)?$',  // ISO8601 duration
      description: 'ISO8601 duration e.g. PT2H, PT1H30M'
    }
  },
  additionalProperties: false
};

export interface PhaseContext {
  phase: string;
  inputs: Record<string, any>;
  dependencies?: string[];
  budgets: {
    tokens: number;
    tools_minutes: number;
    gpu_hours?: number;
  };
  rubrics: Record<string, any>;
  timebox: string;
}

// Validator function
import Ajv from 'ajv';
const ajv = new Ajv();
export const validatePhaseContext = ajv.compile(PhaseContextSchema);
```

**packages/schemas/src/phase/task-spec.ts:**
```typescript
/**
 * TaskSpec - Individual task specification for agents/tools
 * Spec: phase.txt:85-102
 */

export const TaskSpecSchema = {
  $schema: 'https://json-schema.org/draft/2020-12/schema',
  $id: 'schema.phase.taskspec.v1',
  type: 'object',
  required: ['id', 'phase', 'type', 'target', 'input', 'budget'],
  properties: {
    id: { type: 'string', format: 'uuid' },
    phase: { type: 'string' },
    type: { enum: ['agent', 'tool'] },
    target: { type: 'string' },  // agent class name or tool ID
    input: { type: 'object' },
    retries: { type: 'integer', minimum: 0, default: 0 },
    budget: {
      type: 'object',
      required: ['ms'],
      properties: {
        ms: { type: 'integer', minimum: 0 },
        tokens: { type: 'number', minimum: 0 }
      },
      additionalProperties: false
    },
    egress_policy: { type: 'object' },
    idempotence_key: { type: 'string' }  // SHA256 hash
  },
  additionalProperties: false
};

export interface TaskSpec {
  id: string;
  phase: string;
  type: 'agent' | 'tool';
  target: string;
  input: Record<string, any>;
  retries?: number;
  budget: {
    ms: number;
    tokens?: number;
  };
  egress_policy?: Record<string, any>;
  idempotence_key?: string;
}

import Ajv from 'ajv';
const ajv = new Ajv();
export const validateTaskSpec = ajv.compile(TaskSpecSchema);
```

**packages/schemas/src/phase/evidence-pack.ts:**
```typescript
/**
 * EvidencePack - Gate evaluation evidence (generalized for all phases)
 * Spec: phase.txt:107-122, orchestrator.txt:114
 */

export const EvidencePackSchema = {
  $schema: 'https://json-schema.org/draft/2020-12/schema',
  $id: 'schema.phase.evidencepack.v1',
  type: 'object',
  required: ['artifacts', 'guard_reports'],
  properties: {
    artifacts: {
      type: 'array',
      items: { type: 'string' }  // artifact IDs
    },
    guard_reports: {
      type: 'array',
      items: { type: 'object' }  // guard results
    },
    qav_summary: {
      type: 'object',
      properties: {
        questions_count: { type: 'integer' },
        answered_count: { type: 'integer' },
        validated_count: { type: 'integer' },
        grounding_score: { type: 'number', minimum: 0, maximum: 1 },
        assumptions: { type: 'array', items: { type: 'object' } }
      }
    },
    kmap_refs: {
      type: 'array',
      items: { type: 'string' }  // Knowledge Map frame IDs
    },
    metrics: {
      type: 'object',
      properties: {
        duration_ms: { type: 'integer' },
        tokens_used: { type: 'number' },
        tools_minutes: { type: 'number' },
        cost_usd: { type: 'number' }
      }
    }
  },
  additionalProperties: false
};

export interface EvidencePack {
  artifacts: string[];
  guard_reports: Array<Record<string, any>>;
  qav_summary?: {
    questions_count: number;
    answered_count: number;
    validated_count: number;
    grounding_score: number;
    assumptions: Array<Record<string, any>>;
  };
  kmap_refs?: string[];
  metrics?: {
    duration_ms: number;
    tokens_used: number;
    tools_minutes: number;
    cost_usd?: number;
  };
}

import Ajv from 'ajv';
const ajv = new Ajv();
export const validateEvidencePack = ajv.compile(EvidencePackSchema);
```

**packages/schemas/src/phase/index.ts:**
```typescript
export * from './phase-context';
export * from './task-spec';
export * from './evidence-pack';
```

**Effort:** 1 day

---

### 1.3 Phase Event Schemas (7 Structured Events)

**Requirement:** phase.txt:129-144

**Files to Create:**

**packages/event-schemas/src/phase-events.ts:**
```typescript
/**
 * Phase Lifecycle Events (7 types)
 * Spec: phase.txt:129-144
 */

export enum PhaseEventType {
  PHASE_STARTED = 'phase.started',
  PHASE_PROGRESS = 'phase.progress',
  PHASE_STALLED = 'phase.stalled',
  PHASE_READY = 'phase.ready',
  PHASE_GATE_PASSED = 'phase.gate.passed',
  PHASE_GATE_FAILED = 'phase.gate.failed',
  PHASE_ERROR = 'phase.error',
}

// phase.started
export interface PhaseStartedEvent {
  type: PhaseEventType.PHASE_STARTED;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    phase_run_id: string;
    started_at: string;  // ISO8601
  };
}

// phase.progress
export interface PhaseProgressEvent {
  type: PhaseEventType.PHASE_PROGRESS;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    task_id: string;
    pct: number;         // 0-100
    eta: string;         // ISO8601 timestamp
    metrics: {
      tasks_completed: number;
      tasks_total: number;
      tokens_used: number;
    };
  };
}

// phase.stalled
export interface PhaseStalledEvent {
  type: PhaseEventType.PHASE_STALLED;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    task_id: string;
    reason: string;
    last_heartbeat_at: string;  // ISO8601
  };
}

// phase.ready
export interface PhaseReadyEvent {
  type: PhaseEventType.PHASE_READY;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    phase: string;
    artifacts: string[];  // artifact IDs
  };
}

// phase.gate.passed
export interface PhaseGatePassedEvent {
  type: PhaseEventType.PHASE_GATE_PASSED;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    phase: string;
    evidence_pack_id: string;
    passed_at: string;  // ISO8601
    score: number;      // 0-100
  };
}

// phase.gate.failed
export interface PhaseGateFailedEvent {
  type: PhaseEventType.PHASE_GATE_FAILED;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    phase: string;
    reasons: string[];
    evidence_pack_id: string;
    score: number;
    required_actions: string[];
  };
}

// phase.error
export interface PhaseErrorEvent {
  type: PhaseEventType.PHASE_ERROR;
  keys: {
    run_id: string;
    phase: string;
  };
  payload: {
    phase: string;
    error: string;
    retryable: boolean;
    stack?: string;
  };
}

export type PhaseEvent =
  | PhaseStartedEvent
  | PhaseProgressEvent
  | PhaseStalledEvent
  | PhaseReadyEvent
  | PhaseGatePassedEvent
  | PhaseGateFailedEvent
  | PhaseErrorEvent;
```

**Files to Modify:**

**packages/orchestrator-core/src/base/enhanced-phase-coordinator.ts:**
```typescript
// Add event emission at lifecycle points
import { PhaseEventType, PhaseStartedEvent, PhaseProgressEvent, etc } from '@ideamine/event-schemas';

export class EnhancedPhaseCoordinator {
  async execute(ctx: PhaseContext): Promise<PhaseResult> {
    // Emit phase.started
    await this.eventBus.publish<PhaseStartedEvent>({
      type: PhaseEventType.PHASE_STARTED,
      keys: { run_id: ctx.runId, phase: ctx.phase },
      payload: {
        phase_run_id: `${ctx.runId}-${ctx.phase}`,
        started_at: new Date().toISOString(),
      },
    });

    try {
      // ... existing logic

      // Emit phase.progress periodically
      await this.emitProgress(ctx, pct, eta, metrics);

      // ... gate evaluation
      if (gateResult.pass) {
        await this.eventBus.publish<PhaseGatePassedEvent>({
          type: PhaseEventType.PHASE_GATE_PASSED,
          keys: { run_id: ctx.runId, phase: ctx.phase },
          payload: {
            phase: ctx.phase,
            evidence_pack_id: evidencePack.id,
            passed_at: new Date().toISOString(),
            score: gateResult.score,
          },
        });
      } else {
        await this.eventBus.publish<PhaseGateFailedEvent>({
          type: PhaseEventType.PHASE_GATE_FAILED,
          keys: { run_id: ctx.runId, phase: ctx.phase },
          payload: {
            phase: ctx.phase,
            reasons: gateResult.reasons,
            evidence_pack_id: evidencePack.id,
            score: gateResult.score,
            required_actions: gateResult.requiredActions,
          },
        });
      }

      // Emit phase.ready
      await this.eventBus.publish<PhaseReadyEvent>({
        type: PhaseEventType.PHASE_READY,
        keys: { run_id: ctx.runId, phase: ctx.phase },
        payload: {
          phase: ctx.phase,
          artifacts: result.artifacts.map(a => a.id),
        },
      });

    } catch (error) {
      // Emit phase.error
      await this.eventBus.publish<PhaseErrorEvent>({
        type: PhaseEventType.PHASE_ERROR,
        keys: { run_id: ctx.runId, phase: ctx.phase },
        payload: {
          phase: ctx.phase,
          error: error.message,
          retryable: this.isRetryable(error),
          stack: error.stack,
        },
      });
      throw error;
    }
  }
}
```

**Effort:** 1 day

---

### 1.4 Run Plan & Phase Plan Data Structures

**Requirement:** orchestrator.txt:51-53, phase.txt:172

**Files to Create:**

**packages/schemas/src/orchestrator/run-plan.ts:**
```typescript
/**
 * Run Plan - Top-level plan for entire run (idea â†’ GA)
 * Spec: orchestrator.txt:51-53
 */

export interface RunPlan {
  run_id: string;
  tenant_id: string;
  phases: PhasePlanSummary[];
  budgets: {
    total_tokens: number;
    total_tools_minutes: number;
    total_gpu_hours: number;
  };
  policies: {
    no_user_interactions: boolean;
    hallucination_guards_required: boolean;
    security_gates_required: boolean[];
  };
  timeouts: {
    total_timeout_hours: number;  // 20-50h
    phase_timeouts: Record<string, number>;  // hours per phase
  };
  required_evidence: string[];  // list of required evidence types
  created_at: string;
  version: string;  // for deterministic replay
}

export interface PhasePlanSummary {
  phase: string;
  dependencies: string[];
  required_artifacts: string[];
  budgets: {
    tokens: number;
    tools_minutes: number;
  };
  timebox: string;  // ISO8601 duration
}

/**
 * Phase Plan - Detailed plan for single phase execution
 * Spec: phase.txt:172 (PhaseCoordinator builds Phase Plan)
 */
export interface PhasePlan {
  phase: string;
  parallelism: 'sequential' | 'partial' | 'iterative' | number;
  agents: string[];
  tools: string[];
  guards: string[];
  rubrics: Record<string, any>;
  budgets: {
    tokens: number;
    tools_minutes: number;
  };
  timebox: string;
  refinery_config: {
    fission_min_coverage: number;
    fusion_min_consensus: number;
  };
  hash: string;  // SHA256(agents + rubrics + budgets) for deterministic replay
  version: string;
}
```

**packages/orchestrator-core/src/planning/run-planner.ts:**
```typescript
/**
 * Run Planner - Creates Run Plan from IdeaInput
 * Spec: orchestrator.txt:51-53
 */

import { RunPlan, PhasePlanSummary } from '@ideamine/schemas/orchestrator';
import { WorkflowStateMachine } from '../workflow-state';
import { loadPhaseConfig } from '../../agents/src/config/loader';

export class RunPlanner {
  async createRunPlan(ideaInput: any): Promise<RunPlan> {
    const run_id = generateRunId();
    const phases = WorkflowStateMachine.PHASES;

    // Load all phase configs
    const phasePlans: PhasePlanSummary[] = [];
    let totalTokens = 0;
    let totalToolsMinutes = 0;

    for (const phaseConfig of phases) {
      const yamlConfig = await loadPhaseConfig(phaseConfig.phaseId);

      phasePlans.push({
        phase: phaseConfig.phaseId,
        dependencies: phaseConfig.dependencies || [],
        required_artifacts: this.getRequiredArtifacts(phaseConfig.phaseId),
        budgets: yamlConfig.budgets,
        timebox: yamlConfig.timebox,
      });

      totalTokens += yamlConfig.budgets.tokens;
      totalToolsMinutes += yamlConfig.budgets.tools_minutes;
    }

    return {
      run_id,
      tenant_id: ideaInput.tenant_id || 'default',
      phases: phasePlans,
      budgets: {
        total_tokens: totalTokens,
        total_tools_minutes: totalToolsMinutes,
        total_gpu_hours: 0,
      },
      policies: {
        no_user_interactions: true,
        hallucination_guards_required: true,
        security_gates_required: ['security'],
      },
      timeouts: {
        total_timeout_hours: 50,
        phase_timeouts: this.calculatePhaseTimeouts(phasePlans),
      },
      required_evidence: ['EvidencePack', 'SecurityPack', 'TestReports'],
      created_at: new Date().toISOString(),
      version: '1.0.0',
    };
  }

  private getRequiredArtifacts(phase: string): string[] {
    const artifactMap: Record<string, string[]> = {
      intake: ['IdeaSpec', 'Glossary', 'Feasibility'],
      ideation: ['DiscoveryPack', 'Personas', 'UseCases'],
      critique: ['RiskRegister', 'Assumptions'],
      prd: ['PRD', 'RTM', 'UserStories'],
      bizdev: ['BizPack', 'PricingModel', 'GTMPlan'],
      architecture: ['ArchOutline', 'OpenAPI', 'ERD'],
      build: ['RepoManifest', 'CIPipeline', 'InfraModules'],
      security: ['SecurityPack', 'SBOM', 'Signatures'],
      'story-loop': ['CodeArtifacts', 'Tests', 'PRs'],
      qa: ['TestReports', 'CoverageReport', 'PerfReport'],
      aesthetic: ['A11yAudit', 'DesignTokens', 'WebVitals'],
      release: ['ReleaseNotes', 'Deployment', 'SignedImages'],
      beta: ['BetaReport', 'TelemetryConfig', 'Analytics'],
    };
    return artifactMap[phase] || [];
  }

  private calculatePhaseTimeouts(phases: PhasePlanSummary[]): Record<string, number> {
    // Parse ISO8601 duration to hours
    const timeouts: Record<string, number> = {};
    for (const phase of phases) {
      const match = phase.timebox.match(/PT(\d+)H/);
      timeouts[phase.phase] = match ? parseInt(match[1]) : 2;
    }
    return timeouts;
  }
}
```

**Effort:** 2 days

---

### 1.5 Config Loader Enhancement

**Requirement:** phase.txt:273-280, 357-456

**Files to Modify:**

**packages/agents/src/config/loader.ts:**
```typescript
/**
 * Enhanced Config Loader - Loads phase YAML configs
 * Spec: phase.txt:273 (config/ folder), 357-456 (YAML format)
 */

import * as fs from 'fs/promises';
import * as path from 'path';
import * as yaml from 'js-yaml';
import { PhasePlan } from '@ideamine/schemas/orchestrator';
import crypto from 'crypto';

export interface PhaseConfig {
  phase: string;
  parallelism: 'sequential' | 'partial' | 'iterative' | number;
  agents: string[];
  budgets: {
    tokens: number;
    tools_minutes: number;
    gpu_hours?: number;
  };
  rubrics: Record<string, any>;
  allowlisted_tools: string[];
  heartbeat_seconds: number;
  stall_threshold_heartbeats: number;
  refinery: {
    fission_min_coverage: number;
    fusion_min_consensus: number;
  };
  timebox: string;
}

export class ConfigLoader {
  private configCache: Map<string, PhaseConfig> = new Map();

  async loadPhaseConfig(phaseId: string): Promise<PhaseConfig> {
    // Check cache
    if (this.configCache.has(phaseId)) {
      return this.configCache.get(phaseId)!;
    }

    // Load from YAML
    const configPath = path.join(process.cwd(), 'config', `${phaseId}.yaml`);

    try {
      const content = await fs.readFile(configPath, 'utf-8');
      const config = yaml.load(content) as PhaseConfig;

      // Validate config
      this.validateConfig(config);

      // Cache
      this.configCache.set(phaseId, config);

      return config;
    } catch (error) {
      throw new Error(`Failed to load config for phase ${phaseId}: ${error.message}`);
    }
  }

  async derivePhasePlan(phaseId: string, runContext: any): Promise<PhasePlan> {
    const config = await this.loadPhaseConfig(phaseId);

    // Calculate hash for deterministic replay
    const hash = this.calculatePlanHash(config);

    return {
      phase: config.phase,
      parallelism: config.parallelism,
      agents: config.agents,
      tools: config.allowlisted_tools.filter(t => t.startsWith('tool.')),
      guards: config.allowlisted_tools.filter(t => t.startsWith('guard.')),
      rubrics: config.rubrics,
      budgets: {
        tokens: config.budgets.tokens,
        tools_minutes: config.budgets.tools_minutes,
      },
      timebox: config.timebox,
      refinery_config: config.refinery,
      hash,
      version: '1.0.0',
    };
  }

  private calculatePlanHash(config: PhaseConfig): string {
    const hashInput = JSON.stringify({
      agents: config.agents.sort(),
      rubrics: config.rubrics,
      budgets: config.budgets,
    });
    return crypto.createHash('sha256').update(hashInput).digest('hex');
  }

  private validateConfig(config: PhaseConfig): void {
    if (!config.phase) throw new Error('Config missing phase field');
    if (!config.agents || config.agents.length === 0) {
      throw new Error('Config must have at least one agent');
    }
    if (!config.budgets || !config.budgets.tokens) {
      throw new Error('Config missing budgets.tokens');
    }
    if (!config.timebox || !config.timebox.startsWith('PT')) {
      throw new Error('Config timebox must be ISO8601 duration (e.g., PT2H)');
    }
  }
}

export const configLoader = new ConfigLoader();
export const loadPhaseConfig = (phaseId: string) => configLoader.loadPhaseConfig(phaseId);
export const derivePhasePlan = (phaseId: string, runContext: any) =>
  configLoader.derivePhasePlan(phaseId, runContext);
```

**Effort:** 1 day

---

### 1.6 Budget Tracking System

**Requirement:** orchestrator.txt:70-71, phase.txt:120-122

**Files to Create:**

**packages/orchestrator-core/src/budget/budget-tracker.ts:**
```typescript
/**
 * Budget Tracker - Tracks and enforces phase budgets
 * Spec: orchestrator.txt:70-71, phase.txt:120-122
 */

export interface BudgetAllocation {
  phase: string;
  tokens: number;
  tools_minutes: number;
  gpu_hours: number;
}

export interface BudgetUsage {
  tokens_used: number;
  tools_minutes_used: number;
  gpu_hours_used: number;
  last_updated: Date;
}

export class BudgetTracker {
  private allocations: Map<string, BudgetAllocation> = new Map();
  private usage: Map<string, BudgetUsage> = new Map();

  allocate(phaseId: string, budget: BudgetAllocation): void {
    this.allocations.set(phaseId, budget);
    this.usage.set(phaseId, {
      tokens_used: 0,
      tools_minutes_used: 0,
      gpu_hours_used: 0,
      last_updated: new Date(),
    });
  }

  recordTokenUsage(phaseId: string, tokens: number): void {
    const usage = this.usage.get(phaseId);
    if (!usage) throw new Error(`No budget allocated for phase ${phaseId}`);

    usage.tokens_used += tokens;
    usage.last_updated = new Date();

    // Check if over budget
    const allocation = this.allocations.get(phaseId)!;
    if (usage.tokens_used > allocation.tokens) {
      throw new BudgetExceededError(
        `Phase ${phaseId} exceeded token budget: ${usage.tokens_used}/${allocation.tokens}`
      );
    }
  }

  recordToolUsage(phaseId: string, minutes: number): void {
    const usage = this.usage.get(phaseId);
    if (!usage) throw new Error(`No budget allocated for phase ${phaseId}`);

    usage.tools_minutes_used += minutes;
    usage.last_updated = new Date();

    const allocation = this.allocations.get(phaseId)!;
    if (usage.tools_minutes_used > allocation.tools_minutes) {
      throw new BudgetExceededError(
        `Phase ${phaseId} exceeded tools budget: ${usage.tools_minutes_used}/${allocation.tools_minutes}`
      );
    }
  }

  getRemainingBudget(phaseId: string): BudgetAllocation {
    const allocation = this.allocations.get(phaseId);
    const usage = this.usage.get(phaseId);

    if (!allocation || !usage) {
      throw new Error(`No budget allocated for phase ${phaseId}`);
    }

    return {
      phase: phaseId,
      tokens: allocation.tokens - usage.tokens_used,
      tools_minutes: allocation.tools_minutes - usage.tools_minutes_used,
      gpu_hours: allocation.gpu_hours - usage.gpu_hours_used,
    };
  }

  getBudgetUtilization(phaseId: string): number {
    const allocation = this.allocations.get(phaseId);
    const usage = this.usage.get(phaseId);

    if (!allocation || !usage) return 0;

    // Calculate weighted utilization
    const tokenPct = usage.tokens_used / allocation.tokens;
    const toolsPct = usage.tools_minutes_used / allocation.tools_minutes;

    return Math.max(tokenPct, toolsPct);  // return highest utilization
  }

  shouldThrottle(phaseId: string): boolean {
    const utilization = this.getBudgetUtilization(phaseId);
    return utilization > 0.8;  // throttle at 80% budget
  }
}

export class BudgetExceededError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'BudgetExceededError';
  }
}
```

**Effort:** 1 day

---

### 1.7 Database Tables (Foundation)

**Requirement:** phase.txt:109, orchestrator.txt:110-115

**Migration File to Create:**

**migrations/008_foundation_tables.sql:**
```sql
-- Phases table (track phase execution)
CREATE TABLE IF NOT EXISTS phases (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL REFERENCES runs(id) ON DELETE CASCADE,
  phase_id VARCHAR(50) NOT NULL,  -- 'intake', 'ideation', etc.
  status VARCHAR(20) NOT NULL,    -- 'pending', 'running', 'completed', 'failed'
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  budgets JSONB NOT NULL,         -- { tokens, tools_minutes, gpu_hours }
  usage JSONB,                    -- { tokens_used, tools_minutes_used, ... }
  plan_hash VARCHAR(64),          -- SHA256 hash for deterministic replay
  evidence_pack_id UUID,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),

  UNIQUE(run_id, phase_id)
);

CREATE INDEX idx_phases_run_id ON phases(run_id);
CREATE INDEX idx_phases_status ON phases(status);

-- Assumptions table (unknowns become assumptions with mitigation tasks)
CREATE TABLE IF NOT EXISTS assumptions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL REFERENCES runs(id) ON DELETE CASCADE,
  phase_id VARCHAR(50) NOT NULL,
  assumption TEXT NOT NULL,
  rationale TEXT,
  mitigation_task_id UUID,       -- points to tasks table (created later)
  status VARCHAR(20) DEFAULT 'active',  -- 'active', 'validated', 'invalidated'
  created_at TIMESTAMP DEFAULT NOW(),
  validated_at TIMESTAMP,

  INDEX idx_assumptions_run_id (run_id),
  INDEX idx_assumptions_phase (phase_id),
  INDEX idx_assumptions_status (status)
);

-- Add version column to runs table
ALTER TABLE runs ADD COLUMN IF NOT EXISTS version VARCHAR(20) DEFAULT '1.0.0';
ALTER TABLE runs ADD COLUMN IF NOT EXISTS plan_hash VARCHAR(64);

-- Evidence packs table (generalized for all phases)
CREATE TABLE IF NOT EXISTS evidence_packs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL REFERENCES runs(id) ON DELETE CASCADE,
  phase_id VARCHAR(50) NOT NULL,
  artifacts JSONB NOT NULL,       -- array of artifact IDs
  guard_reports JSONB NOT NULL,   -- array of guard results
  qav_summary JSONB,              -- Q/A/V summary
  kmap_refs JSONB,                -- Knowledge Map frame IDs
  metrics JSONB,                  -- duration, tokens, cost
  created_at TIMESTAMP DEFAULT NOW(),

  INDEX idx_evidence_run_id (run_id),
  INDEX idx_evidence_phase (phase_id)
);
```

**Effort:** 1 day

---

**Foundation Layer Total: 10 days**

---

## Autonomy Layer (Week 3-4)

**Goal:** Enable fully autonomous clarification via Q/A/V Triad + Knowledge Refinery

### 2.1 Q/A/V Triad Implementation

**Requirement:** orchestrator.txt:44, 172-175, phase.txt:102-106

**File Structure (from phase.txt:261-264):**
```
packages/agents/src/qav/
  question-agent.ts      (QAQ - Question Agent)
  answer-agent.ts        (QAA - Answer Agent)
  question-validator.ts  (QV - Question Validator)
  index.ts
```

**packages/agents/src/qav/question-agent.ts:**
```typescript
/**
 * Question Agent (QAQ) - Generates decision-changing questions
 * Spec: orchestrator.txt:173, phase.txt:103
 */

import { BaseAgent } from '@ideamine/agent-sdk';

export interface QuestionGenerationInput {
  phase: string;
  artifacts: any[];        // phase artifacts so far
  context: Record<string, any>;
  rubrics: Record<string, any>;
}

export interface Question {
  id: string;
  text: string;
  category: 'clarification' | 'validation' | 'assumption' | 'risk';
  priority: 'high' | 'medium' | 'low';
  decision_impact: string;  // what decision this affects
  context: string;          // why this question matters
}

export class QuestionAgent extends BaseAgent {
  async execute(input: QuestionGenerationInput): Promise<Question[]> {
    const { phase, artifacts, context, rubrics } = input;

    // Analyze artifacts for gaps/ambiguities
    const gaps = await this.analyzeGaps(artifacts, rubrics);

    // Generate questions targeting gaps
    const questions: Question[] = [];

    for (const gap of gaps) {
      const question = await this.generateQuestion(gap, phase);
      questions.push(question);
    }

    // Prioritize questions by decision impact
    questions.sort((a, b) => {
      const priorityOrder = { high: 0, medium: 1, low: 2 };
      return priorityOrder[a.priority] - priorityOrder[b.priority];
    });

    return questions;
  }

  private async analyzeGaps(artifacts: any[], rubrics: Record<string, any>): Promise<any[]> {
    const gaps = [];

    // Check for missing required fields
    // Check for ambiguous statements
    // Check for contradictions
    // Check for assumptions without evidence

    // Use LLM to find gaps
    const prompt = `
      Analyze these artifacts and identify critical gaps, ambiguities, or missing information:

      Artifacts: ${JSON.stringify(artifacts)}
      Required rubrics: ${JSON.stringify(rubrics)}

      Return gaps as JSON array with: { type, description, severity }
    `;

    const result = await this.llm.invoke(prompt);
    return JSON.parse(result.content);
  }

  private async generateQuestion(gap: any, phase: string): Promise<Question> {
    const prompt = `
      Generate a decision-changing question for this gap in the ${phase} phase:

      Gap: ${gap.description}
      Type: ${gap.type}
      Severity: ${gap.severity}

      The question should:
      1. Be specific and actionable
      2. Target a real decision point
      3. Be answerable with tools/artifacts/reasoning

      Return JSON: { text, category, decision_impact, context }
    `;

    const result = await this.llm.invoke(prompt);
    const parsed = JSON.parse(result.content);

    return {
      id: crypto.randomUUID(),
      text: parsed.text,
      category: parsed.category,
      priority: gap.severity === 'critical' ? 'high' : 'medium',
      decision_impact: parsed.decision_impact,
      context: parsed.context,
    };
  }
}
```

**packages/agents/src/qav/answer-agent.ts:**
```typescript
/**
 * Answer Agent (QAA) - Answers questions using artifacts + tools
 * Spec: orchestrator.txt:173, phase.txt:104
 */

import { BaseAgent } from '@ideamine/agent-sdk';
import { ToolRegistry } from '@ideamine/orchestrator-core/analyzer';

export interface AnswerGenerationInput {
  questions: Question[];
  artifacts: any[];
  allowlisted_tools: string[];
  phase: string;
}

export interface Answer {
  question_id: string;
  answer: string | 'UNKNOWN';
  confidence: number;        // 0-1
  citations: string[];       // artifact IDs or tool results
  reasoning: string;
  next_steps?: string[];     // if UNKNOWN
}

export class AnswerAgent extends BaseAgent {
  constructor(
    private toolRegistry: ToolRegistry,
  ) {
    super();
  }

  async execute(input: AnswerGenerationInput): Promise<Answer[]> {
    const answers: Answer[] = [];

    for (const question of input.questions) {
      const answer = await this.answerQuestion(
        question,
        input.artifacts,
        input.allowlisted_tools,
        input.phase
      );
      answers.push(answer);
    }

    return answers;
  }

  private async answerQuestion(
    question: Question,
    artifacts: any[],
    allowlistedTools: string[],
    phase: string
  ): Promise<Answer> {
    // Step 1: Search artifacts for answer
    const artifactEvidence = await this.searchArtifacts(question, artifacts);

    // Step 2: If not found, try tools
    let toolEvidence = null;
    if (!artifactEvidence || artifactEvidence.confidence < 0.7) {
      toolEvidence = await this.searchWithTools(question, allowlistedTools);
    }

    // Step 3: Synthesize answer
    const evidence = toolEvidence || artifactEvidence;

    if (!evidence || evidence.confidence < 0.6) {
      // UNKNOWN - register as assumption
      return {
        question_id: question.id,
        answer: 'UNKNOWN',
        confidence: 0,
        citations: [],
        reasoning: 'Insufficient evidence in artifacts and tools',
        next_steps: await this.generateNextSteps(question),
      };
    }

    return {
      question_id: question.id,
      answer: evidence.answer,
      confidence: evidence.confidence,
      citations: evidence.citations,
      reasoning: evidence.reasoning,
    };
  }

  private async searchArtifacts(question: Question, artifacts: any[]): Promise<any> {
    // Use RAG over artifacts
    const prompt = `
      Answer this question using ONLY the provided artifacts:

      Question: ${question.text}
      Context: ${question.context}

      Artifacts: ${JSON.stringify(artifacts)}

      Return JSON: { answer, confidence (0-1), citations (artifact IDs), reasoning }
      If you cannot answer with certainty, set confidence < 0.6
    `;

    const result = await this.llm.invoke(prompt);
    return JSON.parse(result.content);
  }

  private async searchWithTools(question: Question, allowlistedTools: string[]): Promise<any> {
    // Determine which tool can answer this
    const relevantTools = allowlistedTools.filter(t =>
      this.isRelevantTool(t, question)
    );

    for (const toolId of relevantTools) {
      const tool = await this.toolRegistry.getTool(toolId);

      try {
        const result = await tool.execute({ query: question.text });

        // Parse tool result and extract answer
        const answer = await this.extractAnswerFromToolResult(result, question);

        if (answer.confidence > 0.6) {
          return answer;
        }
      } catch (error) {
        // Tool failed, try next
        continue;
      }
    }

    return null;
  }

  private async generateNextSteps(question: Question): Promise<string[]> {
    // Generate mitigation tasks for UNKNOWN answers
    const prompt = `
      This question cannot be answered with current information:

      Question: ${question.text}
      Decision Impact: ${question.decision_impact}

      Generate 2-3 concrete next steps to gather the information needed.
      Return as JSON array of strings.
    `;

    const result = await this.llm.invoke(prompt);
    return JSON.parse(result.content);
  }
}
```

**packages/agents/src/qav/question-validator.ts:**
```typescript
/**
 * Question Validator (QV) - Validates Qâ†”A bindings
 * Spec: orchestrator.txt:174, phase.txt:105
 */

import { BaseAgent } from '@ideamine/agent-sdk';

export interface ValidationInput {
  questions: Question[];
  answers: Answer[];
}

export interface ValidationResult {
  question_id: string;
  answer_id: string;
  accepted: boolean;
  grounding_score: number;        // 0-1
  completeness_score: number;     // 0-1
  specificity_score: number;      // 0-1
  consistency_score: number;      // 0-1
  overall_score: number;          // 0-1
  issues: string[];               // if not accepted
  feedback: string;               // for regeneration
}

export class QuestionValidator extends BaseAgent {
  private thresholds = {
    grounding: 0.7,
    completeness: 0.7,
    specificity: 0.6,
    consistency: 0.8,
    overall: 0.7,
  };

  async execute(input: ValidationInput): Promise<ValidationResult[]> {
    const results: ValidationResult[] = [];

    for (const question of input.questions) {
      const answer = input.answers.find(a => a.question_id === question.id);

      if (!answer) {
        throw new Error(`No answer found for question ${question.id}`);
      }

      const validation = await this.validateBinding(question, answer);
      results.push(validation);
    }

    return results;
  }

  private async validateBinding(question: Question, answer: Answer): Promise<ValidationResult> {
    // If answer is UNKNOWN, auto-reject (will become ASSUMPTION)
    if (answer.answer === 'UNKNOWN') {
      return {
        question_id: question.id,
        answer_id: answer.question_id,
        accepted: false,
        grounding_score: 0,
        completeness_score: 0,
        specificity_score: 0,
        consistency_score: 0,
        overall_score: 0,
        issues: ['Answer is UNKNOWN - will register as ASSUMPTION'],
        feedback: 'Gather more information or make explicit assumption',
      };
    }

    // Calculate scores
    const groundingScore = await this.scoreGrounding(answer);
    const completenessScore = await this.scoreCompleteness(question, answer);
    const specificityScore = await this.scoreSpecificity(answer);
    const consistencyScore = await this.scoreConsistency(answer);

    const overallScore = (
      groundingScore +
      completenessScore +
      specificityScore +
      consistencyScore
    ) / 4;

    const accepted =
      groundingScore >= this.thresholds.grounding &&
      completenessScore >= this.thresholds.completeness &&
      specificityScore >= this.thresholds.specificity &&
      consistencyScore >= this.thresholds.consistency &&
      overallScore >= this.thresholds.overall;

    const issues = [];
    if (groundingScore < this.thresholds.grounding) issues.push('Insufficient grounding/citations');
    if (completenessScore < this.thresholds.completeness) issues.push('Incomplete answer');
    if (specificityScore < this.thresholds.specificity) issues.push('Too vague');
    if (consistencyScore < this.thresholds.consistency) issues.push('Inconsistent with other answers');

    return {
      question_id: question.id,
      answer_id: answer.question_id,
      accepted,
      grounding_score: groundingScore,
      completeness_score: completenessScore,
      specificity_score: specificityScore,
      consistency_score: consistencyScore,
      overall_score: overallScore,
      issues,
      feedback: accepted ? 'Accepted' : issues.join('; '),
    };
  }

  private async scoreGrounding(answer: Answer): Promise<number> {
    // Score based on citations and confidence
    if (answer.citations.length === 0) return 0;
    if (answer.confidence < 0.6) return answer.confidence * 0.5;

    // Check if citations are real/valid
    // ...

    return Math.min(answer.confidence, 1.0);
  }

  private async scoreCompleteness(question: Question, answer: Answer): Promise<number> {
    const prompt = `
      Does this answer fully address the question?

      Question: ${question.text}
      Answer: ${answer.answer}

      Return JSON: { complete: boolean, missing: string[], score: 0-1 }
    `;

    const result = await this.llm.invoke(prompt);
    const parsed = JSON.parse(result.content);
    return parsed.score;
  }

  private async scoreSpecificity(answer: Answer): Promise<number> {
    // Check for vague language
    const vagueTerms = ['maybe', 'possibly', 'might', 'could be', 'somewhat'];
    const text = answer.answer.toString().toLowerCase();

    const vagueCount = vagueTerms.filter(term => text.includes(term)).length;

    return Math.max(0, 1 - (vagueCount * 0.2));
  }

  private async scoreConsistency(answer: Answer): Promise<number> {
    // Check if answer is internally consistent
    // and consistent with previous answers
    // ...

    return 1.0;  // placeholder
  }
}
```

**packages/agents/src/qav/index.ts:**
```typescript
export * from './question-agent';
export * from './answer-agent';
export * from './question-validator';
```

**Effort:** 5 days

---

### 2.2 Knowledge Refinery Integration

**Requirement:** orchestrator.txt:175, phase.txt:106

**Files to Modify:**

**packages/orchestrator-core/src/base/refinery-adapter.ts:**
```typescript
/**
 * Knowledge Refinery Adapter - Integrates Q/A/V with Refinery
 * Spec: orchestrator.txt:175, phase.txt:106
 */

import { Question, Answer, ValidationResult } from '@ideamine/agents/qav';
import { RefineryClient } from '../knowledge-map/km-client';

export interface QAVBundle {
  questions: Question[];
  answers: Answer[];
  validations: ValidationResult[];
  phase: string;
  run_id: string;
}

export class RefineryAdapter {
  constructor(
    private refineryClient: RefineryClient,
  ) {}

  /**
   * Push Q/A/V bundle to Knowledge Refinery
   * - Accepted Q/A pairs â†’ Fission â†’ Grounding â†’ Fusion â†’ Knowledge Map
   * - Rejected Q/A pairs â†’ regenerate
   * - UNKNOWN answers â†’ ASSUMPTIONS registry
   */
  async processQAVBundle(bundle: QAVBundle): Promise<{
    kmap_refs: string[];
    assumptions: any[];
  }> {
    const acceptedPairs = bundle.validations
      .filter(v => v.accepted)
      .map(v => ({
        question: bundle.questions.find(q => q.id === v.question_id)!,
        answer: bundle.answers.find(a => a.question_id === v.question_id)!,
      }));

    const unknownAnswers = bundle.answers.filter(a => a.answer === 'UNKNOWN');

    // Send accepted Q/A to Refinery for Fission
    const frames = await this.fissionQAPairs(acceptedPairs, bundle.phase);

    // Ground frames (check against existing knowledge)
    const groundedFrames = await this.refineryClient.groundFrames(frames);

    // Fusion (cluster similar frames, merge, create canonical frames)
    const canonicalFrames = await this.refineryClient.fusionFrames(
      groundedFrames,
      bundle.phase
    );

    // Emit kmap.delta event
    await this.emitKMapDelta(canonicalFrames, bundle.run_id, bundle.phase);

    // Register UNKNOWN answers as ASSUMPTIONS
    const assumptions = await this.registerAssumptions(
      unknownAnswers,
      bundle.run_id,
      bundle.phase
    );

    return {
      kmap_refs: canonicalFrames.map(f => f.id),
      assumptions,
    };
  }

  private async fissionQAPairs(
    pairs: Array<{ question: Question; answer: Answer }>,
    phase: string
  ): Promise<any[]> {
    // Fission: break Q/A pairs into atomic knowledge frames
    const frames = [];

    for (const { question, answer } of pairs) {
      // Extract atomic facts from answer
      const atomicFacts = await this.extractAtomicFacts(answer);

      for (const fact of atomicFacts) {
        frames.push({
          id: crypto.randomUUID(),
          type: 'fact',
          content: fact,
          source: 'qav',
          phase,
          question_id: question.id,
          citations: answer.citations,
          confidence: answer.confidence,
        });
      }
    }

    return frames;
  }

  private async extractAtomicFacts(answer: Answer): Promise<string[]> {
    const prompt = `
      Break this answer into atomic facts (one fact per sentence):

      Answer: ${answer.answer}

      Return JSON array of strings (one fact per string).
    `;

    const result = await this.llm.invoke(prompt);
    return JSON.parse(result.content);
  }

  private async emitKMapDelta(
    frames: any[],
    runId: string,
    phase: string
  ): Promise<void> {
    await this.eventBus.publish({
      type: 'kmap.delta.created',
      keys: { run_id: runId, phase },
      payload: {
        frame_ids: frames.map(f => f.id),
        count: frames.length,
        source: 'qav',
      },
    });
  }

  private async registerAssumptions(
    unknownAnswers: Answer[],
    runId: string,
    phase: string
  ): Promise<any[]> {
    const assumptions = [];

    for (const answer of unknownAnswers) {
      const assumption = {
        id: crypto.randomUUID(),
        run_id: runId,
        phase,
        assumption: `Question: ${answer.question_id} - Answer UNKNOWN`,
        rationale: answer.reasoning,
        mitigation_tasks: answer.next_steps || [],
        status: 'active',
      };

      // Save to DB
      await this.db.query(`
        INSERT INTO assumptions (id, run_id, phase_id, assumption, rationale, status)
        VALUES ($1, $2, $3, $4, $5, $6)
      `, [assumption.id, runId, phase, assumption.assumption, assumption.rationale, 'active']);

      assumptions.push(assumption);
    }

    return assumptions;
  }
}
```

**Effort:** 2 days

---

### 2.3 Autonomous Clarification Loop

**Requirement:** orchestrator.txt:61-63, 136-138

**Files to Modify:**

**packages/orchestrator-core/src/base/enhanced-phase-coordinator.ts:**
```typescript
/**
 * Enhanced Phase Coordinator - Add Q/A/V clarification loop
 * Spec: orchestrator.txt:61-63 (no user prompts), phase.txt:161-164
 */

import { QuestionAgent, AnswerAgent, QuestionValidator } from '@ideamine/agents/qav';
import { RefineryAdapter } from './refinery-adapter';

export class EnhancedPhaseCoordinator {
  private questionAgent: QuestionAgent;
  private answerAgent: AnswerAgent;
  private questionValidator: QuestionValidator;
  private refineryAdapter: RefineryAdapter;

  async execute(ctx: PhaseContext): Promise<PhaseResult> {
    // ... existing fan-out/fan-in logic

    const draft = await this.fanIn(agentResults);

    // Q/A/V Loop (autonomous clarification - NO USER)
    const qavResult = await this.runQAVLoop(draft, ctx);

    // Push Q/A/V to Knowledge Refinery
    const refineryResult = await this.refineryAdapter.processQAVBundle({
      questions: qavResult.questions,
      answers: qavResult.answers,
      validations: qavResult.validations,
      phase: ctx.phase,
      run_id: ctx.runId,
    });

    // ... guards & gate
  }

  private async runQAVLoop(
    draft: any,
    ctx: PhaseContext,
    maxIterations: number = 3
  ): Promise<{
    questions: Question[];
    answers: Answer[];
    validations: ValidationResult[];
  }> {
    let iteration = 0;
    let allAccepted = false;

    let questions: Question[] = [];
    let answers: Answer[] = [];
    let validations: ValidationResult[] = [];

    while (!allAccepted && iteration < maxIterations) {
      // Step 1: Question Agent generates questions
      questions = await this.questionAgent.execute({
        phase: ctx.phase,
        artifacts: draft.artifacts,
        context: ctx.inputs,
        rubrics: ctx.rubrics,
      });

      if (questions.length === 0) {
        // No questions â†’ artifacts are complete
        allAccepted = true;
        break;
      }

      // Step 2: Answer Agent answers questions
      answers = await this.answerAgent.execute({
        questions,
        artifacts: draft.artifacts,
        allowlisted_tools: ctx.allowlisted_tools,
        phase: ctx.phase,
      });

      // Step 3: Question Validator validates Q/A bindings
      validations = await this.questionValidator.execute({
        questions,
        answers,
      });

      // Check if all accepted
      const rejectedCount = validations.filter(v => !v.accepted).length;
      if (rejectedCount === 0) {
        allAccepted = true;
      } else {
        // Regenerate answers for rejected questions
        const rejectedQuestions = validations
          .filter(v => !v.accepted)
          .map(v => questions.find(q => q.id === v.question_id)!);

        // ... retry with stricter prompts or different tools
        iteration++;
      }
    }

    // After loop: any UNKNOWN answers become ASSUMPTIONS
    // (handled by RefineryAdapter)

    return { questions, answers, validations };
  }
}
```

**Effort:** 1 day

---

**Autonomy Layer Total: 8 days**

---

## Execution Layer (Week 5-6)

**Goal:** Build custom orchestration engine (no n8n, no Temporal) with job queue, worker pool, scheduler, checkpoints

### 3.1 Job Queue (Redis Streams)

**Requirement:** phase.txt:105, 117-128

**Files to Create:**

**packages/orchestrator-core/src/queue/queue.ts:**
```typescript
/**
 * Job Queue - Redis Streams implementation
 * Spec: phase.txt:105, 117-128
 */

import Redis from 'ioredis';
import crypto from 'crypto';

export interface QueueMessage {
  key: string;           // idempotence key
  payload: any;
}

export class JobQueue {
  private redis: Redis;
  private topics = {
    TASKS: 'tasks',
    HEARTBEATS: 'heartbeats',
    EVENTS: 'events',
  };

  constructor(redisUrl: string) {
    this.redis = new Redis(redisUrl);
  }

  /**
   * Enqueue message with idempotence key
   * Spec: phase.txt:117-120
   */
  async enqueue(topic: string, msg: any, key: string): Promise<void> {
    // Check if key already processed (idempotence)
    const processed = await this.redis.get(`idempotence:${key}`);
    if (processed) {
      console.log(`Skipping duplicate task with key ${key}`);
      return;
    }

    // Add to stream
    await this.redis.xadd(
      topic,
      '*',  // auto-generate ID
      'key', key,
      'payload', JSON.stringify(msg)
    );

    // Mark key as processed (TTL 24h)
    await this.redis.setex(`idempotence:${key}`, 86400, '1');
  }

  /**
   * Consume messages from topic
   * Spec: phase.txt:122-128
   */
  async consume(
    topic: string,
    consumerGroup: string,
    consumerName: string,
    handler: (msg: any) => Promise<boolean>
  ): Promise<void> {
    // Create consumer group if not exists
    try {
      await this.redis.xgroup('CREATE', topic, consumerGroup, '0', 'MKSTREAM');
    } catch (error) {
      // Group already exists
    }

    // Consume loop
    while (true) {
      const results = await this.redis.xreadgroup(
        'GROUP', consumerGroup, consumerName,
        'BLOCK', 5000,  // 5s timeout
        'COUNT', 10,
        'STREAMS', topic, '>'
      );

      if (!results || results.length === 0) continue;

      for (const [stream, messages] of results) {
        for (const [id, fields] of messages) {
          const key = fields[fields.indexOf('key') + 1];
          const payload = JSON.parse(fields[fields.indexOf('payload') + 1]);

          try {
            const ok = await handler(payload);

            if (ok) {
              // Acknowledge message
              await this.redis.xack(topic, consumerGroup, id);
            } else {
              // Retry later (don't ack)
              console.log(`Handler returned false for message ${id}, will retry`);
            }
          } catch (error) {
            console.error(`Error processing message ${id}:`, error);
            // Don't ack - will be redelivered
          }
        }
      }
    }
  }

  /**
   * Get queue depth (for adaptive concurrency)
   */
  async getQueueDepth(topic: string): Promise<number> {
    const info = await this.redis.xinfo('STREAM', topic);
    // Parse info array to get length
    const lengthIndex = info.indexOf('length');
    return parseInt(info[lengthIndex + 1]);
  }

  /**
   * Generate idempotence key
   */
  static generateKey(phase: string, inputs: any, version: string): string {
    const data = JSON.stringify({ phase, inputs, version });
    return crypto.createHash('sha256').update(data).digest('hex');
  }
}
```

**Effort:** 2 days

---

### 3.2 Checkpoint System

**Requirement:** orchestrator.txt:24, 68, 122, phase.txt:37, 135-145

**Files to Create:**

**packages/orchestrator-core/src/checkpoint/checkpoint-manager.ts:**
```typescript
/**
 * Checkpoint Manager - Save/load checkpoints for long-running tasks
 * Spec: orchestrator.txt:68, phase.txt:37, 135-145
 */

export interface Checkpoint {
  task_id: string;
  token: string;           // continuation token (opaque)
  data: any;               // checkpoint data (agent-specific)
  created_at: Date;
}

export class CheckpointManager {
  constructor(
    private db: any,  // database connection
  ) {}

  /**
   * Save checkpoint for task
   * Spec: phase.txt:140 (saveCheckpoint)
   */
  async saveCheckpoint(taskId: string, token: string, data: any): Promise<void> {
    await this.db.query(`
      INSERT INTO checkpoints (task_id, token, data, created_at)
      VALUES ($1, $2, $3, NOW())
      ON CONFLICT (task_id) DO UPDATE
      SET token = $2, data = $3, created_at = NOW()
    `, [taskId, token, JSON.stringify(data)]);
  }

  /**
   * Load latest checkpoint for task
   * Spec: phase.txt:135 (loadCheckpoint)
   */
  async loadCheckpoint(taskId: string): Promise<Checkpoint | null> {
    const result = await this.db.query(`
      SELECT task_id, token, data, created_at
      FROM checkpoints
      WHERE task_id = $1
      ORDER BY created_at DESC
      LIMIT 1
    `, [taskId]);

    if (result.rows.length === 0) return null;

    const row = result.rows[0];
    return {
      task_id: row.task_id,
      token: row.token,
      data: row.data,
      created_at: row.created_at,
    };
  }

  /**
   * Resume task from checkpoint
   */
  async resumeTask(taskId: string, executor: (ctx: any) => Promise<any>): Promise<any> {
    const checkpoint = await this.loadCheckpoint(taskId);

    if (!checkpoint) {
      // No checkpoint - start from beginning
      return executor({ checkpoint: null });
    }

    // Resume from checkpoint
    return executor({
      checkpoint: checkpoint.token,
      ...checkpoint.data,
    });
  }
}
```

**packages/orchestrator-core/src/database/checkpoint-repository.ts:**
```typescript
/**
 * Checkpoint Repository - DB access for checkpoints
 */

export class CheckpointRepository {
  constructor(private db: any) {}

  async create(checkpoint: Checkpoint): Promise<void> {
    await this.db.query(`
      INSERT INTO checkpoints (id, task_id, token, data, created_at)
      VALUES ($1, $2, $3, $4, $5)
    `, [
      crypto.randomUUID(),
      checkpoint.task_id,
      checkpoint.token,
      JSON.stringify(checkpoint.data),
      new Date(),
    ]);
  }

  async getLatest(taskId: string): Promise<Checkpoint | null> {
    const result = await this.db.query(`
      SELECT * FROM checkpoints
      WHERE task_id = $1
      ORDER BY created_at DESC
      LIMIT 1
    `, [taskId]);

    if (result.rows.length === 0) return null;

    const row = result.rows[0];
    return {
      task_id: row.task_id,
      token: row.token,
      data: row.data,
      created_at: row.created_at,
    };
  }

  async deleteForTask(taskId: string): Promise<void> {
    await this.db.query(`DELETE FROM checkpoints WHERE task_id = $1`, [taskId]);
  }
}
```

**Effort:** 2 days

---

### 3.3 WorkerPool Implementation

**Requirement:** phase.txt:107, 133-145

**Files to Create:**

**packages/orchestrator-core/src/worker/worker.ts:**
```typescript
/**
 * Worker - Executes tasks from queue with heartbeats + checkpoints
 * Spec: phase.txt:133-145
 */

import { TaskSpec } from '@ideamine/schemas/phase';
import { CheckpointManager } from '../checkpoint/checkpoint-manager';
import { EventPublisher } from '../event-publisher';

export class Worker {
  private heartbeatInterval: NodeJS.Timeout | null = null;

  constructor(
    private workerId: string,
    private checkpointManager: CheckpointManager,
    private eventPublisher: EventPublisher,
  ) {}

  /**
   * Execute task with heartbeats and checkpoints
   * Spec: phase.txt:133-145
   */
  async runTask(task: TaskSpec): Promise<{ ok: boolean; result?: any; error?: string; ms: number }> {
    const t0 = Date.now();

    // Load checkpoint if exists
    const ckpt = await this.checkpointManager.loadCheckpoint(task.id);
    const ctx = { ...task.input, checkpoint: ckpt?.token };

    // Start heartbeat
    this.heartbeatInterval = setInterval(
      () => this.emitHeartbeat(task.id, this.estimatePct(), this.estimateEta()),
      60000  // every 60s
    );

    try {
      // Execute agent or tool
      const result = await this.executeAgentOrTool(
        task.type,
        task.target,
        ctx,
        (token, data) => this.checkpointManager.saveCheckpoint(task.id, token, data)
      );

      // Stop heartbeat
      this.stopHeartbeat();

      return {
        ok: true,
        result,
        ms: Date.now() - t0,
      };
    } catch (error) {
      // Stop heartbeat
      this.stopHeartbeat();

      return {
        ok: false,
        error: error.message,
        ms: Date.now() - t0,
      };
    }
  }

  private async executeAgentOrTool(
    type: 'agent' | 'tool',
    target: string,
    ctx: any,
    saveCheckpoint: (token: string, data: any) => Promise<void>
  ): Promise<any> {
    if (type === 'agent') {
      const AgentClass = await this.loadAgent(target);
      const agent = new AgentClass();

      // Pass saveCheckpoint callback to agent
      agent.setCheckpointCallback(saveCheckpoint);

      return agent.execute(ctx);
    } else {
      const tool = await this.loadTool(target);
      return tool.execute(ctx);
    }
  }

  private emitHeartbeat(taskId: string, pct: number, eta: string): void {
    this.eventPublisher.publish({
      type: 'task.heartbeat',
      keys: { task_id: taskId, worker_id: this.workerId },
      payload: {
        pct,
        eta,
        timestamp: new Date().toISOString(),
      },
    });
  }

  private stopHeartbeat(): void {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
      this.heartbeatInterval = null;
    }
  }

  private estimatePct(): number {
    // Placeholder - agents should report progress
    return 50;
  }

  private estimateEta(): string {
    // Placeholder
    return new Date(Date.now() + 300000).toISOString();  // +5 min
  }
}
```

**packages/orchestrator-core/src/worker/worker-pool.ts:**
```typescript
/**
 * WorkerPool - Manages pool of workers consuming from queue
 * Spec: phase.txt:107
 */

import { Worker } from './worker';
import { JobQueue } from '../queue/queue';
import { CheckpointManager } from '../checkpoint/checkpoint-manager';

export class WorkerPool {
  private workers: Worker[] = [];

  constructor(
    private size: number,
    private queue: JobQueue,
    private checkpointManager: CheckpointManager,
  ) {}

  async start(): Promise<void> {
    // Spawn workers
    for (let i = 0; i < this.size; i++) {
      const worker = new Worker(
        `worker-${i}`,
        this.checkpointManager,
        this.eventPublisher
      );
      this.workers.push(worker);

      // Start consuming tasks
      this.queue.consume(
        'tasks',
        'phase-workers',
        `worker-${i}`,
        async (task) => {
          const result = await worker.runTask(task);
          return result.ok;  // true = ack, false = retry
        }
      );
    }
  }

  async stop(): Promise<void> {
    // Gracefully stop all workers
    // (implementation omitted for brevity)
  }

  async scale(newSize: number): Promise<void> {
    // Add or remove workers dynamically
    if (newSize > this.size) {
      // Add workers
      const toAdd = newSize - this.size;
      for (let i = 0; i < toAdd; i++) {
        // ... spawn new worker
      }
    } else if (newSize < this.size) {
      // Remove workers
      const toRemove = this.size - newSize;
      for (let i = 0; i < toRemove; i++) {
        // ... stop worker
      }
    }
    this.size = newSize;
  }
}
```

**Effort:** 4 days

---

### 3.4 Scheduler Service

**Requirement:** phase.txt:106, 172

**Files to Create:**

**packages/orchestrator-core/src/scheduler/scheduler.ts:**
```typescript
/**
 * Scheduler - Turns PhasePlan into TaskSpecs and enqueues them
 * Spec: phase.txt:106, 172
 */

import { PhasePlan } from '@ideamine/schemas/orchestrator';
import { TaskSpec } from '@ideamine/schemas/phase';
import { JobQueue } from '../queue/queue';
import crypto from 'crypto';

export class Scheduler {
  constructor(
    private queue: JobQueue,
  ) {}

  /**
   * Schedule all agents/tools from PhasePlan
   */
  async schedule(plan: PhasePlan, ctx: PhaseContext): Promise<string[]> {
    const taskIds: string[] = [];

    // Generate TaskSpecs for each agent
    const taskSpecs = await this.generateTaskSpecs(plan, ctx);

    // Enqueue with idempotence keys
    for (const taskSpec of taskSpecs) {
      const key = JobQueue.generateKey(plan.phase, taskSpec.input, plan.version);
      taskSpec.idempotence_key = key;

      await this.queue.enqueue('tasks', taskSpec, key);
      taskIds.push(taskSpec.id);
    }

    return taskIds;
  }

  private async generateTaskSpecs(plan: PhasePlan, ctx: PhaseContext): Promise<TaskSpec[]> {
    const specs: TaskSpec[] = [];

    for (const agentName of plan.agents) {
      specs.push({
        id: crypto.randomUUID(),
        phase: plan.phase,
        type: 'agent',
        target: agentName,
        input: ctx.inputs,
        retries: 3,
        budget: {
          ms: this.parseTimebox(plan.timebox),
          tokens: plan.budgets.tokens / plan.agents.length,  // split budget
        },
        egress_policy: {},
      });
    }

    return specs;
  }

  private parseTimebox(timebox: string): number {
    // Parse ISO8601 duration to milliseconds
    // PT2H â†’ 7200000ms
    const match = timebox.match(/PT(\d+)H/);
    if (match) {
      return parseInt(match[1]) * 3600000;
    }
    return 7200000;  // default 2h
  }

  /**
   * Shard large task into smaller chunks
   * Spec: phase.txt:60 (batching/sharding)
   */
  async shardTask(taskSpec: TaskSpec, shardSize: number): Promise<TaskSpec[]> {
    // Example: if task.input has 1000 items, split into shards of 100
    const items = taskSpec.input.items || [];

    if (items.length <= shardSize) {
      return [taskSpec];
    }

    const shards: TaskSpec[] = [];

    for (let i = 0; i < items.length; i += shardSize) {
      const shard = items.slice(i, i + shardSize);

      shards.push({
        ...taskSpec,
        id: `${taskSpec.id}-shard-${i / shardSize}`,
        input: {
          ...taskSpec.input,
          items: shard,
          shard_index: i / shardSize,
          total_shards: Math.ceil(items.length / shardSize),
        },
      });
    }

    return shards;
  }
}
```

**Effort:** 2 days

---

### 3.5 Timer Service

**Requirement:** phase.txt:108, 150-156

**Files to Create:**

**packages/orchestrator-core/src/timer/timer-service.ts:**
```typescript
/**
 * Timer Service - Durable timers for retries and timeboxes
 * Spec: phase.txt:108, 150-156
 */

import { TaskSpec } from '@ideamine/schemas/phase';
import { JobQueue } from '../queue/queue';

export interface Timer {
  task_id: string;
  fire_at: number;      // Unix timestamp (ms)
  action: 'retry' | 'timeout';
  payload: any;
}

export class TimerService {
  private timers: Map<string, NodeJS.Timeout> = new Map();

  constructor(
    private db: any,
    private queue: JobQueue,
  ) {}

  /**
   * Schedule retry with exponential backoff
   * Spec: phase.txt:150-156
   */
  async scheduleRetry(
    task: TaskSpec,
    attempt: number,
    policy: { base: number; maxMs: number }
  ): Promise<void> {
    const delay = Math.min(policy.base * Math.pow(2, attempt), policy.maxMs);
    const fireAt = Date.now() + delay;

    // Insert timer in DB (for durability)
    await this.insertTimer({
      task_id: task.id,
      fire_at: fireAt,
      action: 'retry',
      payload: { ...task, attempt: attempt + 1 },
    });

    // Schedule in-memory timer
    const timeout = setTimeout(async () => {
      await this.fireTimer(task.id);
    }, delay);

    this.timers.set(task.id, timeout);
  }

  /**
   * Schedule timeout (phase timebox enforcement)
   */
  async scheduleTimeout(phaseId: string, timeboxMs: number): Promise<void> {
    const fireAt = Date.now() + timeboxMs;

    await this.insertTimer({
      task_id: `timeout-${phaseId}`,
      fire_at: fireAt,
      action: 'timeout',
      payload: { phaseId },
    });

    const timeout = setTimeout(async () => {
      await this.fireTimer(`timeout-${phaseId}`);
    }, timeboxMs);

    this.timers.set(`timeout-${phaseId}`, timeout);
  }

  private async insertTimer(timer: Timer): Promise<void> {
    await this.db.query(`
      INSERT INTO timers (task_id, fire_at, action, payload)
      VALUES ($1, $2, $3, $4)
    `, [timer.task_id, new Date(timer.fire_at), timer.action, JSON.stringify(timer.payload)]);
  }

  private async fireTimer(taskId: string): Promise<void> {
    // Load timer from DB
    const result = await this.db.query(`
      SELECT * FROM timers WHERE task_id = $1
    `, [taskId]);

    if (result.rows.length === 0) return;

    const timer = result.rows[0];

    if (timer.action === 'retry') {
      // Re-enqueue task
      const task = timer.payload;
      const key = JobQueue.generateKey(task.phase, task.input, task.attempt.toString());
      await this.queue.enqueue('tasks', task, key);
    } else if (timer.action === 'timeout') {
      // Emit timeout event
      await this.eventPublisher.publish({
        type: 'phase.timeout',
        keys: { phase: timer.payload.phaseId },
        payload: { message: 'Phase timebox exceeded' },
      });
    }

    // Delete timer
    await this.db.query(`DELETE FROM timers WHERE task_id = $1`, [taskId]);
    this.timers.delete(taskId);
  }

  /**
   * Resume timers after restart (durability)
   */
  async resumeTimers(): Promise<void> {
    const result = await this.db.query(`
      SELECT * FROM timers WHERE fire_at > NOW()
    `);

    for (const row of result.rows) {
      const delay = new Date(row.fire_at).getTime() - Date.now();

      const timeout = setTimeout(async () => {
        await this.fireTimer(row.task_id);
      }, delay);

      this.timers.set(row.task_id, timeout);
    }
  }
}
```

**Effort:** 2 days

---

### 3.6 State Store Tables

**Requirement:** phase.txt:109

**Migration File to Create:**

**migrations/009_execution_tables.sql:**
```sql
-- Tasks table (track individual agent/tool executions)
CREATE TABLE IF NOT EXISTS tasks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  phase_id UUID NOT NULL REFERENCES phases(id) ON DELETE CASCADE,
  type VARCHAR(10) NOT NULL CHECK (type IN ('agent', 'tool')),
  target VARCHAR(100) NOT NULL,   -- agent class name or tool ID
  input JSONB NOT NULL,
  status VARCHAR(20) NOT NULL DEFAULT 'pending',  -- 'pending', 'running', 'completed', 'failed'
  retries INTEGER DEFAULT 0,
  result JSONB,
  error TEXT,
  cost JSONB,                      -- { tokens, tools_minutes, usd }
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW(),

  INDEX idx_tasks_phase (phase_id),
  INDEX idx_tasks_status (status),
  INDEX idx_tasks_type (type)
);

-- Checkpoints table
CREATE TABLE IF NOT EXISTS checkpoints (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
  token VARCHAR(100) NOT NULL,     -- continuation token
  data JSONB NOT NULL,             -- checkpoint data
  created_at TIMESTAMP DEFAULT NOW(),

  UNIQUE(task_id),                 -- one checkpoint per task
  INDEX idx_checkpoints_task (task_id)
);

-- Events table (structured event log)
CREATE TABLE IF NOT EXISTS events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL REFERENCES runs(id) ON DELETE CASCADE,
  phase_id VARCHAR(50),
  event_type VARCHAR(50) NOT NULL,
  payload JSONB NOT NULL,
  timestamp TIMESTAMP DEFAULT NOW(),

  INDEX idx_events_run (run_id),
  INDEX idx_events_phase (phase_id),
  INDEX idx_events_type (event_type),
  INDEX idx_events_timestamp (timestamp)
);

-- Timers table (durable timers)
CREATE TABLE IF NOT EXISTS timers (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  task_id VARCHAR(100) NOT NULL UNIQUE,
  fire_at TIMESTAMP NOT NULL,
  action VARCHAR(20) NOT NULL CHECK (action IN ('retry', 'timeout')),
  payload JSONB NOT NULL,
  created_at TIMESTAMP DEFAULT NOW(),

  INDEX idx_timers_fire_at (fire_at)
);
```

**Effort:** 1 day

---

**Execution Layer Total: 13 days** (rounded up from 12)

---

## Resilience Layer (Week 7-8)

**Goal:** Unsticker routines, heartbeat monitoring, retry policies, fallbacks

### 4.1 Heartbeat Monitoring System

**Requirement:** orchestrator.txt:132-133, phase.txt:84

**Files to Create:**

**packages/orchestrator-core/src/runners/heartbeat.ts:**
```typescript
/**
 * Heartbeat Monitor - Detects stalls via missed heartbeats
 * Spec: orchestrator.txt:132-133, phase.txt:84
 */

export interface HeartbeatConfig {
  interval_seconds: number;         // e.g., 60
  stall_threshold_heartbeats: number;  // e.g., 3
}

export class HeartbeatMonitor {
  private lastHeartbeats: Map<string, Date> = new Map();
  private stallCheckInterval: NodeJS.Timeout;

  constructor(
    private config: HeartbeatConfig,
    private onStallDetected: (taskId: string) => Promise<void>,
  ) {
    // Check for stalls every interval
    this.stallCheckInterval = setInterval(
      () => this.checkForStalls(),
      config.interval_seconds * 1000
    );
  }

  recordHeartbeat(taskId: string): void {
    this.lastHeartbeats.set(taskId, new Date());
  }

  private async checkForStalls(): Promise<void> {
    const now = Date.now();
    const stallThresholdMs = this.config.interval_seconds * this.config.stall_threshold_heartbeats * 1000;

    for (const [taskId, lastHeartbeat] of this.lastHeartbeats.entries()) {
      const elapsedMs = now - lastHeartbeat.getTime();

      if (elapsedMs > stallThresholdMs) {
        console.warn(`Task ${taskId} stalled - no heartbeat for ${elapsedMs}ms`);

        // Emit stalled event
        await this.eventPublisher.publish({
          type: PhaseEventType.PHASE_STALLED,
          keys: { task_id: taskId },
          payload: {
            task_id: taskId,
            reason: `No heartbeat for ${Math.floor(elapsedMs / 1000)}s`,
            last_heartbeat_at: lastHeartbeat.toISOString(),
          },
        });

        // Trigger unsticker
        await this.onStallDetected(taskId);

        // Remove from tracking (unsticker will handle)
        this.lastHeartbeats.delete(taskId);
      }
    }
  }

  stop(): void {
    clearInterval(this.stallCheckInterval);
  }
}
```

**Files to Modify:**

**packages/agent-sdk/src/base-agent.ts:**
```typescript
/**
 * Add heartbeat emission to all agents
 */

export abstract class BaseAgent {
  private checkpointCallback?: (token: string, data: any) => Promise<void>;
  private heartbeatCallback?: () => void;

  setCheckpointCallback(callback: (token: string, data: any) => Promise<void>): void {
    this.checkpointCallback = callback;
  }

  setHeartbeatCallback(callback: () => void): void {
    this.heartbeatCallback = callback;
  }

  protected async emitHeartbeat(): Promise<void> {
    if (this.heartbeatCallback) {
      this.heartbeatCallback();
    }
  }

  protected async saveCheckpoint(token: string, data: any): Promise<void> {
    if (this.checkpointCallback) {
      await this.checkpointCallback(token, data);
    }
  }

  // Agents should call emitHeartbeat() periodically
  async execute(input: any): Promise<any> {
    // Example: emit heartbeat every major step
    await this.emitHeartbeat();

    // ... agent logic

    await this.emitHeartbeat();

    return result;
  }
}
```

**Effort:** 2 days

---

### 4.2 Unsticker Routines

**Requirement:** orchestrator.txt:128-150, phase.txt:82-90

**Files to Create:**

**packages/orchestrator-core/src/heal/heartbeatGuard.ts:** (already covered above)

**packages/orchestrator-core/src/heal/slopeMonitor.ts:**
```typescript
/**
 * Progress Slope Monitor - Detects plateaus and adjusts strategy
 * Spec: orchestrator.txt:134-135, phase.txt:85
 */

export class ProgressSlopeMonitor {
  private progressHistory: Map<string, number[]> = new Map();  // taskId â†’ [pct values]

  recordProgress(taskId: string, pct: number): void {
    if (!this.progressHistory.has(taskId)) {
      this.progressHistory.set(taskId, []);
    }

    const history = this.progressHistory.get(taskId)!;
    history.push(pct);

    // Keep only last 10 data points
    if (history.length > 10) {
      history.shift();
    }
  }

  detectPlateau(taskId: string): boolean {
    const history = this.progressHistory.get(taskId);
    if (!history || history.length < 5) return false;

    // Calculate slope (linear regression)
    const slope = this.calculateSlope(history);

    // If slope < 0.5% per interval, it's a plateau
    return slope < 0.005;
  }

  private calculateSlope(values: number[]): number {
    const n = values.length;
    const xMean = (n - 1) / 2;
    const yMean = values.reduce((a, b) => a + b, 0) / n;

    let numerator = 0;
    let denominator = 0;

    for (let i = 0; i < n; i++) {
      numerator += (i - xMean) * (values[i] - yMean);
      denominator += Math.pow(i - xMean, 2);
    }

    return numerator / denominator;
  }

  async adjustStrategy(taskId: string): Promise<void> {
    // Try smaller batch size
    // Try alternate tool
    // Try stricter prompts

    console.log(`Adjusting strategy for task ${taskId} due to plateau`);

    // Emit event for supervisor to handle
    await this.eventPublisher.publish({
      type: 'task.plateau',
      keys: { task_id: taskId },
      payload: {
        task_id: taskId,
        reason: 'Low progress slope detected',
      },
    });
  }
}
```

**packages/orchestrator-core/src/heal/fallbackLadder.ts:**
```typescript
/**
 * Tool Fallback Ladder - Try alternate tools when primary fails
 * Spec: orchestrator.txt:139-141, phase.txt:87
 */

export class FallbackLadder {
  async executWithFallback(
    primaryTool: string,
    allowlistedTools: string[],
    input: any
  ): Promise<any> {
    // Build fallback ladder
    const ladder = this.buildLadder(primaryTool, allowlistedTools);

    for (const toolId of ladder) {
      try {
        const tool = await this.toolRegistry.getTool(toolId);
        const result = await tool.execute(input);
        return result;
      } catch (error) {
        console.warn(`Tool ${toolId} failed, trying next in ladder`);
        continue;
      }
    }

    throw new Error(`All tools in fallback ladder failed for ${primaryTool}`);
  }

  private buildLadder(primaryTool: string, allowlistedTools: string[]): string[] {
    // Primary tool first
    const ladder = [primaryTool];

    // Then similar tools from allowlist
    const category = this.getToolCategory(primaryTool);
    const similarTools = allowlistedTools.filter(t =>
      this.getToolCategory(t) === category && t !== primaryTool
    );

    ladder.push(...similarTools);

    return ladder;
  }

  private getToolCategory(toolId: string): string {
    // e.g., "tool.intake.normalizer" â†’ "intake"
    const parts = toolId.split('.');
    return parts[1] || 'unknown';
  }
}
```

**packages/orchestrator-core/src/heal/chunker.ts:**
```typescript
/**
 * Spec Shrink / Chunking - Split massive work into smaller chunks
 * Spec: orchestrator.txt:142-144, phase.txt:88
 */

export class SpecShrinker {
  async chunkLargeCodebase(
    codebase: { files: string[]; totalLOC: number },
    maxChunkLOC: number = 10000
  ): Promise<Array<{ files: string[]; estimatedLOC: number }>> {
    if (codebase.totalLOC <= maxChunkLOC) {
      return [codebase];
    }

    // Split by stories/services/modules
    const chunks: Array<{ files: string[]; estimatedLOC: number }> = [];

    // Group files by directory (assume each dir is a service/module)
    const filesByDir = this.groupFilesByDirectory(codebase.files);

    let currentChunk: string[] = [];
    let currentLOC = 0;

    for (const [dir, files] of Object.entries(filesByDir)) {
      const estimatedDirLOC = files.length * 100;  // rough estimate

      if (currentLOC + estimatedDirLOC > maxChunkLOC && currentChunk.length > 0) {
        // Flush current chunk
        chunks.push({ files: currentChunk, estimatedLOC: currentLOC });
        currentChunk = [];
        currentLOC = 0;
      }

      currentChunk.push(...files);
      currentLOC += estimatedDirLOC;
    }

    if (currentChunk.length > 0) {
      chunks.push({ files: currentChunk, estimatedLOC: currentLOC });
    }

    return chunks;
  }

  private groupFilesByDirectory(files: string[]): Record<string, string[]> {
    const groups: Record<string, string[]> = {};

    for (const file of files) {
      const dir = path.dirname(file);
      if (!groups[dir]) groups[dir] = [];
      groups[dir].push(file);
    }

    return groups;
  }
}
```

**Effort:** 3 days

---

### 4.3 Retry Policy Engine

**Requirement:** orchestrator.txt:145-147, phase.txt:89

**Files to Create:**

**packages/orchestrator-core/src/utils/retries.ts:**
```typescript
/**
 * Retry Policy Engine - Configurable retries per error type
 * Spec: orchestrator.txt:145-147, phase.txt:89
 */

export enum ErrorType {
  TRANSIENT = 'transient',         // network errors, timeouts
  SCHEMA = 'schema',               // schema validation failures
  TOOL_INFRA = 'tool_infra',       // tool execution failures
  HALLUCINATION = 'hallucination', // guard detected hallucination
}

export interface RetryPolicy {
  type: ErrorType;
  max_retries: number;
  backoff: 'exponential' | 'linear' | 'constant';
  base_delay_ms: number;
  max_delay_ms: number;
  escalation?: 'fix-synth' | 'alternate-tool' | 'fail';
}

export class RetryPolicyEngine {
  private policies: Record<ErrorType, RetryPolicy> = {
    [ErrorType.TRANSIENT]: {
      type: ErrorType.TRANSIENT,
      max_retries: 5,
      backoff: 'exponential',
      base_delay_ms: 1000,
      max_delay_ms: 60000,
    },
    [ErrorType.SCHEMA]: {
      type: ErrorType.SCHEMA,
      max_retries: 1,
      backoff: 'constant',
      base_delay_ms: 0,
      max_delay_ms: 0,
      escalation: 'fix-synth',
    },
    [ErrorType.TOOL_INFRA]: {
      type: ErrorType.TOOL_INFRA,
      max_retries: 3,
      backoff: 'exponential',
      base_delay_ms: 2000,
      max_delay_ms: 30000,
      escalation: 'alternate-tool',
    },
    [ErrorType.HALLUCINATION]: {
      type: ErrorType.HALLUCINATION,
      max_retries: 2,
      backoff: 'constant',
      base_delay_ms: 0,
      max_delay_ms: 0,
      escalation: 'fail',
    },
  };

  async executeWithRetry<T>(
    fn: () => Promise<T>,
    errorType: ErrorType,
    attempt: number = 0
  ): Promise<T> {
    const policy = this.policies[errorType];

    try {
      return await fn();
    } catch (error) {
      if (attempt >= policy.max_retries) {
        // Escalate
        if (policy.escalation === 'fix-synth') {
          return this.escalateToFixSynth(error);
        } else if (policy.escalation === 'alternate-tool') {
          throw new Error(`Alternate tool escalation not implemented`);
        } else {
          throw error;
        }
      }

      // Calculate delay
      const delay = this.calculateDelay(policy, attempt);

      console.log(`Retry attempt ${attempt + 1}/${policy.max_retries} after ${delay}ms`);

      await this.sleep(delay);

      return this.executeWithRetry(fn, errorType, attempt + 1);
    }
  }

  private calculateDelay(policy: RetryPolicy, attempt: number): number {
    let delay = policy.base_delay_ms;

    if (policy.backoff === 'exponential') {
      delay = policy.base_delay_ms * Math.pow(2, attempt);
    } else if (policy.backoff === 'linear') {
      delay = policy.base_delay_ms * (attempt + 1);
    }

    return Math.min(delay, policy.max_delay_ms);
  }

  private async escalateToFixSynth(error: Error): Promise<any> {
    // Call Fix-Synth agent to auto-repair schema
    console.log('Escalating to Fix-Synth agent');
    // ... implementation
    throw error;  // for now
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

**Effort:** 2 days

---

### 4.4 Supervisor Enhancement

**Requirement:** orchestrator.txt:41 (Supervisors), 65 (stall detection)

**Files to Modify:**

**packages/orchestrator-core/src/supervisor/supervisor.ts:**
```typescript
/**
 * Enhanced Supervisor - Orchestrates all unsticker routines
 */

import { HeartbeatMonitor } from '../runners/heartbeat';
import { ProgressSlopeMonitor } from '../heal/slopeMonitor';
import { FallbackLadder } from '../heal/fallbackLadder';
import { SpecShrinker } from '../heal/chunker';
import { RetryPolicyEngine, ErrorType } from '../utils/retries';

export class Supervisor {
  private heartbeatMonitor: HeartbeatMonitor;
  private slopeMonitor: ProgressSlopeMonitor;
  private fallbackLadder: FallbackLadder;
  private specShrinker: SpecShrinker;
  private retryEngine: RetryPolicyEngine;

  constructor() {
    this.heartbeatMonitor = new HeartbeatMonitor(
      { interval_seconds: 60, stall_threshold_heartbeats: 3 },
      (taskId) => this.handleStall(taskId)
    );
    this.slopeMonitor = new ProgressSlopeMonitor();
    this.fallbackLadder = new FallbackLadder();
    this.specShrinker = new SpecShrinker();
    this.retryEngine = new RetryPolicyEngine();
  }

  async handleStall(taskId: string): Promise<void> {
    console.log(`Handling stall for task ${taskId}`);

    // Strategy 1: Check progress slope
    if (this.slopeMonitor.detectPlateau(taskId)) {
      await this.slopeMonitor.adjustStrategy(taskId);
      return;
    }

    // Strategy 2: Try alternate tool (fallback ladder)
    // ...

    // Strategy 3: Chunk the work
    // ...

    // Strategy 4: Retry with different parameters
    await this.retryEngine.executeWithRetry(
      () => this.retryTask(taskId),
      ErrorType.TRANSIENT
    );
  }

  private async retryTask(taskId: string): Promise<void> {
    // Re-enqueue task with adjusted parameters
    // ...
  }
}
```

**Effort:** 1 day

---

**Resilience Layer Total: 8 days**

---

## Observability Layer (Week 9-10)

[Content continues but character limit reached. Document would continue with:
- 5.1 Run Ledger Implementation
- 5.2 Metrics Collection
- 5.3 Provenance Tracking
- 5.4 OpenTelemetry Integration
- 5.5 Evidence Pack Generalization

Then Production Hardening layer with:
- 6.1 Dashboards
- 6.2 RBAC
- 6.3 Versioning
- 6.4 Testing Strategy
- 6.5 DAG Execution
- 6.6 Fan-Out/Fan-In
- 6.7 Loop-Until-Pass Gate

And concluding sections:
- Database Schema (all tables)
- Complete File Structure
- Configuration Files
- Testing Strategy
- Deployment Guide
]

---

**Document continues... (character limit reached)**

Would you like me to continue with the remaining layers (Observability, Production Hardening) and concluding sections?
